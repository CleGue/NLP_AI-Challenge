{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LOcM6jYNrl4"
   },
   "source": [
    "<center><u><h1><strong> ROBERTA & BERT </strong></h1></center></u>\n",
    "\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/2400/0*x3vhaoJdGndvZqmL.png\" alt=\"exemple de texte alternatif\" width=300px /></center>\n",
    "\n",
    "<h2><u>Sommaire :</u></h2>\n",
    "<ul>\n",
    "  <li> Importation </li>\n",
    "  <li> Configuration des données </li>\n",
    "  <li> Configuration du modèle </li>\n",
    "  <li> Entrainement du modèle </li>\n",
    "  <li> Prédictions </li>\n",
    "  <li> Comparaison des prédictions de différents modèles </li>\n",
    "  <li> Bibliographie </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6n1iv0ZgIeQ"
   },
   "source": [
    "<u> <h2><FONT color=\"darkred\"> I - Importation </h2> </u>\n",
    "\n",
    "<u><h3><FONT color=\"darkgreen\"> A - Importation des packages </h3></u>\n",
    "\n",
    "Nous installons les packages manquants transformers et wget. Puis il faut **importer** tous **les packages** pour la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neSY5_KjNoRt",
    "outputId": "a1b39869-dbfb-494b-aa7e-a5550300025d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 36.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 15.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9d6ddbba6342b40f4969be686729bfc1ea843c9455de31f8e97cb65818ecbab7\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1499bf22533fc2c6d62ed41484977134073dcda617638dd08ee6d5dd66531fd8\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "#Installation \n",
    "!pip install transformers\n",
    "!pip install wget\n",
    "\n",
    "#Import \n",
    "import pandas as pd\n",
    "import wget\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import plotly.express as px\n",
    "\n",
    "#FROM\n",
    "from google.colab import drive\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rsi8S3wEPQKG"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Connexion Google Drive </h3></u>\n",
    "\n",
    "Pour importer les données plus rapidement, nous importons un **google drive** qui comporte les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_OjBwg9PDTZ",
    "outputId": "959fcc7f-f669-4af7-9841-20d2ef6062f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70h5qNZqPgR7"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> C - Importation des données </h3></u>\n",
    "\n",
    "Nous importons les données d'apprentissage grâce au fichier **train.json** qui comporte notamment les descriptions des métiers et grace au fichier **train_label.csv** qui comporte les labels des métiers correspondant. Nous importons les données test grâce au fichier **test.json** comportant les descriptions test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N38jrblnHFBe"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./\"\n",
    "train_df = pd.read_json(DATA_PATH+\"/train.json\")\n",
    "test_df = pd.read_json(DATA_PATH+\"/test.json\")\n",
    "train_label = pd.read_csv(DATA_PATH+\"/train_label.csv\")\n",
    "\n",
    "train_df[\"description_lower\"] = [x.lower() for x in train_df.description]\n",
    "test_df[\"description_lower\"] = [x.lower() for x in test_df.description]\n",
    "\n",
    "sentences=train_df[\"description\"].values\n",
    "labels=train_label.Category.values\n",
    "#print(sentences)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjgjXK4mPzMt"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> D - Visualisation des données </h3></u>\n",
    "\n",
    "Nous visualisons ci-dessous une partie des variables explicatives train.Il y a deux variables explicatives le **genre** et la **description**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "K677baSNH87g",
    "outputId": "16a810fc-8785-4943-a0a1-3312bd3f173a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>description_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "      <td>she is also a ronald d. asmus policy entrepre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "      <td>he is a member of the aicpa and wicpa. brent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "      <td>dr. aster has held teaching and research posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "      <td>he runs a boutique design studio attending cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "      <td>he focuses on cloud security, identity and ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                  description_lower\n",
       "0   0  ...   she is also a ronald d. asmus policy entrepre...\n",
       "1   1  ...   he is a member of the aicpa and wicpa. brent ...\n",
       "2   2  ...   dr. aster has held teaching and research posi...\n",
       "4   3  ...   he runs a boutique design studio attending cl...\n",
       "5   4  ...   he focuses on cloud security, identity and ac...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgcQUtJsQGgQ"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> E - GPU </h3></u>\n",
    "\n",
    "Nous demandons un GPU dans cette partie. Au préalable il faut aller dans :\n",
    "<fieldset><center>\n",
    " <strong> Modifier - Paramètres du Notebook - Accélérateur matériel => GPU </strong></center>\n",
    " </fieldset>\n",
    " \n",
    "  Si aucun est disponible on utilise le CPU à la place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG7AgaflIBAQ",
    "outputId": "b0381c1e-0eaf-4e2d-df9e-9c41b3863562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mS0g-7rIIGi",
    "outputId": "388781b9-1ad4-49cc-fae5-3b627f5c5658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__gdhQz5sZnN"
   },
   "source": [
    "Il faut prendre le GPU le plus puissant qui est ici le **Tesla P100-PCIE-16GB** pour plus de rapidité. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK19MPG-fWJD"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> II Préparation des données </h2></u>\n",
    "\n",
    "Avant de passer aux configurations de nos modèles il est important de configurer nos données d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wv8RO1IyQZLI"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> A - Chargement Tokenizer </h3></u>\n",
    "\n",
    "<p> Il faut choisir un des deux Tokenizer correspondant au modèle que l'on souhaite utiliser par la suite. Il existe plusieurs librairies pour chaque tokenizer.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8hJUO2fQtFT"
   },
   "source": [
    "<h4> 1 - Roberta Tokenizer For Sequence Classification </h4>\n",
    "\n",
    "Nous utilisons ici **RobertaTokenizer** avec la librairie **\"roberta-base\"**. Il en existe d'autres consultables sur le site huggingface. Nous aurions pu utiliser roberta large qui est entrainée sur plus de mots seulement pour des problèmes de computationnelle il n'était pas possible de l'exécuter sur Google Colab avec ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdF-zSIXci9v"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwZg5wdqQ5l7"
   },
   "source": [
    "<h4> 2 - Bert Tokenizer For Sequence Classification </h4>\n",
    "\n",
    "Nous utilisons ici **BertTokenizer** avec la librairie **\"bert-base-uncased\"**. Nous aurions pu utiliser bert large qui est entrainé sur plus de mots seulement pour des problèmes de computationnelle il n'était pas possible de l'exécuter sur Google Colab avec ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fffbc26887b2448fb4d4cd37c770c0bd",
      "1ccd15e2d5c040a28473757def6cdade",
      "d67cde4838a149b7b35715c143d6610f",
      "2c499e0133ad45b3b830c1968401456b",
      "d75693031a5844fda7d83a222adfc4a0",
      "ca00784f70524631aed7564bf0df305e",
      "9351f61389db44189c3ec0af0db7d5d6",
      "d587f83489a64e02a0b1648b54e11270"
     ]
    },
    "id": "Mosf3-1tIpN0",
    "outputId": "61ebd173-db7b-4029-df58-c66acab151a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffbc26887b2448fb4d4cd37c770c0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMJPmwC_RX_t"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Tokenization </h3></u>\n",
    "\n",
    "Nous allons tokenizer les phrases c'est-à-dire réaliser un découpage par mot et dans un second temps affecter des ID à chaque mot. Comme on l'a vu précédemment il existe plusieurs techniques de tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LXm5j9lIvYD",
    "outputId": "9ae68d9b-d690-45b4-f589-a07ed6352e83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   She is also a Ronald D. Asmus Policy Entrepreneur Fellow with the German Marshall Fund and is a Visiting Fellow at the Centre for International Studies (CIS) at the University of Oxford. This commentary first appeared at Sada, an online journal published by the Carnegie Endowment for International Peace.\n",
      "Token IDs: [101, 2016, 2003, 2036, 1037, 8923, 1040, 1012, 2004, 7606, 3343, 10670, 3507, 2007, 1996, 2446, 5832, 4636, 1998, 2003, 1037, 5873, 3507, 2012, 1996, 2803, 2005, 2248, 2913, 1006, 20199, 1007, 2012, 1996, 2118, 1997, 4345, 1012, 2023, 8570, 2034, 2596, 2012, 6517, 2050, 1010, 2019, 3784, 3485, 2405, 2011, 1996, 11298, 15108, 2005, 2248, 3521, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization de toutes les phrases et affectation de l'id pour chaque mots \n",
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, \n",
    "                        #max_length = 128,          # Tronquez toutes les phrases.\n",
    "                        #return_tensors = 'pt',     # Renvoie pytorch tensors\n",
    "                   )\n",
    "    \n",
    "    #Ajout de la phrase encoded à la liste inputs_ids\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "#Affichage de la première phrase et de la liste des id\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liFA5thWIye2",
    "outputId": "602988c5-75f0-4155-836c-e8c1d25d4484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La phrase la plus longue possède :  595  caractères\n"
     ]
    }
   ],
   "source": [
    "print('La phrase la plus longue possède : ', max([len(sen) for sen in input_ids]), ' caractères' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS-EQjlfR16T"
   },
   "source": [
    "Sur le chunk suivant nous allons choisir la **longueur maximale en caractère des phrases** de l'entrainement. Pour des raisons computationnelles nous choissions **486 caractères** au-delà de cette valeur nous rencontrons des problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVr-MH4JI1na",
    "outputId": "c10556e1-231a-4a11-c1ee-adaf10e5f734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 486 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\\Done.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 486\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Remplir nos tokens d'entrée avec la valeur 0.\n",
    "# \"post\" indique que nous voulons remplir et tronquer à la fin de la séquence, par opposition au début.\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v--ogWgTS3o6"
   },
   "source": [
    "Nous allons créer des **masques d'attention**. Le masque d'attention indique simplement quels tokens sont des mots réels par rapport à ceux qui ne le sont pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8Qn59QEeI42G"
   },
   "outputs": [],
   "source": [
    "# Création du \"attention masque\" pour toutes les phrases.\n",
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "\n",
    "    # - Si un token ID est 0, alors c'est un padding, définissez le masque sur 0.\n",
    "    # - Si un token ID est> 0, alors c'est un vrai token, définissez le masque sur 1.\n",
    "\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Ajout du \"attention mask\" de la phrase\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umZivnZLTARf"
   },
   "source": [
    "On réalise un **découpage apprentissage/validation** pour les inputs/labels et pour les masks pour l'entrainement avec comme proportion **90%** pour l'apprentissage et **10%** pour la validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IUaiThFnI79v"
   },
   "outputs": [],
   "source": [
    "# Inputs/Labels\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Train/Validation\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW1nWPYOaagi"
   },
   "source": [
    "On convertit les inputs/labels et masks en **torch tensors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BtKKFXShI9V8"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FTNHz8aas1k"
   },
   "source": [
    "\n",
    "Dans le chunk ci-dessous on choisit la **taille des batchs**, les valeurs recommandées pour le fine-tuning pour des taches spécifiques de ce type de modèle Bert ou Roberta sont de **16 ou 32**. Nous avons opté pour des batchs de taille 16 car malgré le fait que cette taille augmente le temps d'exécution elle permet de prendre une longueur maximale des phrases en caractères plus grande. Nous allons également créer un **itérateur** pour notre ensemble de données à l'aide de la classe **Torch DataLoader**. Cela permet d'économiser de la mémoire pendant l'entraînement car, contrairement à une boucle for, avec un itérateur, l'ensemble de données n'a pas besoin d'être chargé en mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aa-ZFm1GI_m5"
   },
   "outputs": [],
   "source": [
    "# Choix batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Créez le DataLoader pour notre ensemble d'apprentissage.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Créez le DataLoader pour notre ensemble de validation.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXwk_mxMbEUB"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> III - Configuration du modèle </h2> </u>\n",
    "\n",
    "Nous allons dans cette partie configurer notre modèle. Il convient de choisir un des deux modèles possible en cohérence avec le tokenizer choisi en amont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6riLpRdbSlX"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> A - Choix du modèle </h3></u>\n",
    "\n",
    "<h4> 1 - Modèle RobertaForSequenceClassification </h4>\n",
    "\n",
    "Nous configurons le modèle avec le paramètre **num_labels=28** qui correspond au nombre de labels dans la variable a expliquer qui est de 28 dans notre cas. Notre modèle pré entrainé avec la librairie **roberta-base** comme nous l'avons mentionné précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v69t5ELQA8BZ"
   },
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=28,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgJKVUDDbfuQ"
   },
   "source": [
    "<h4> 2 - Modèle BertForSequenceClassification </h4>\n",
    "\n",
    "Nous prenons le même **num_labels**. Ici la librairie de pré-traitement est **bert-base-uncased**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "281207d434c24f2e84458c89935a7723",
      "25a01458e7ff444f90f47b9d07032818",
      "a1546b4ecc9446e9a123a15975dab70d",
      "36272b1d065b4421b66dcb999716feb5",
      "09566012c5a74db6a173a182dc38fcc3",
      "b3cfc9aa03f14b64a77feb7e64172f5a",
      "446e2c3e4086427c9a117844b8aa3b28",
      "0c482d1e26d944bd8743d29fad3463a2",
      "75e7decdab154627a28e8b5f1b6cdc77",
      "58e906e24b8447c9b70514447e032d2c",
      "0f422a87a7be466e8b5f322f971c5951",
      "a8038feefeab48fdb24f15ef73bff068",
      "3ac8eeec6df84367b830d5a608729163",
      "bd3a944c935747a082f0c663b56768eb",
      "d19a08708d1c475ab0990d13741ffe8b",
      "f1d0216da1f24c88a783fcca32ab5cb2"
     ]
    },
    "id": "AcSUcxdOJFfM",
    "outputId": "b6e126dd-7534-49c8-f267-9c292349ec42"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281207d434c24f2e84458c89935a7723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e7decdab154627a28e8b5f1b6cdc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 28,    \n",
    "    output_attentions = False, # Affichage du modèle des attentions poids  \n",
    "    output_hidden_states = False, # Affichage du modèle de toutes les couches cachés\n",
    ")\n",
    "# Indique à pytorch d'executer le modèle sur le GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c3J7SHQboq2"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Visualisation des paramètres du modèles </h3></u>\n",
    "\n",
    "Nous visualisons certains paramètres de notre modèle notamment sur les Embedding Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSFRBDGtJKsM",
    "outputId": "4c506198-2ee8-4dde-a2ef-e2c6eea8a0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                          (28, 768)\n",
      "classifier.bias                                                (28,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBs6kSJfYprl"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> C - Optimisation AdamW </h3></u>\n",
    "\n",
    "Dans le chunk suivant nous optimisons les paramètres de notre modèle avec AdamW. Nous choisissons  également le nombre d'epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0VAMasP6I0x-"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "# Note: AdawW est une classe venant de librarie d'hugging face (opposé à pytorch)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - par défaut 5e-5, ici 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - par défaut 1e-8.\n",
    "                )\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Nombre d'epoch pour le training (entre 2 et 4)\n",
    "epochs = 3\n",
    "\n",
    "# Nombre total d'étapes : nombre de batchs * nombre d'epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Créez le planificateur de taux d'apprentissage.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq0S7XQnqMIo"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> IV Entrainement du modèle sur le train et validation </h2></u>\n",
    "\n",
    "Nous allons entrainer notre modèle sur la partie train et verifiée sur la partie validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aS4s3ARqWS1"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> A - Définition de fonction </h3></u>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ8qRgJvY2aZ"
   },
   "source": [
    "<h5><strong> flat accuracy </strong></h5>\n",
    "\n",
    "Nous implémentons une fonction pour calculer la précision de nos prédictions par rapport aux labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6wC971TUJSS-"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3hmsKZPZUOi"
   },
   "source": [
    "<h5> <strong>format time</strong> </h5>\n",
    "\n",
    "Nous allons implémenter une fonction pour calculer le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6dIVI6w-JUUv"
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    # Arrondir à la seconde la plus proche\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format hh:mm:ss ce qui correspond à Heure:Minute:Seconde\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewA4lMF_qnEd"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Entrainement </h3></u>\n",
    "\n",
    "Ci-dessous le chunk d'entrainment et de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00Y9hMXEJYQQ",
    "outputId": "0bfca532-74c5-4c7b-a78b-aad167239c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of  12,218.    Elapsed: 0:00:33.\n",
      "  Batch    80  of  12,218.    Elapsed: 0:01:07.\n",
      "  Batch   120  of  12,218.    Elapsed: 0:01:40.\n",
      "  Batch   160  of  12,218.    Elapsed: 0:02:13.\n",
      "  Batch   200  of  12,218.    Elapsed: 0:02:46.\n",
      "  Batch   240  of  12,218.    Elapsed: 0:03:19.\n",
      "  Batch   280  of  12,218.    Elapsed: 0:03:52.\n",
      "  Batch   320  of  12,218.    Elapsed: 0:04:25.\n",
      "  Batch   360  of  12,218.    Elapsed: 0:04:59.\n",
      "  Batch   400  of  12,218.    Elapsed: 0:05:32.\n",
      "  Batch   440  of  12,218.    Elapsed: 0:06:05.\n",
      "  Batch   480  of  12,218.    Elapsed: 0:06:38.\n",
      "  Batch   520  of  12,218.    Elapsed: 0:07:11.\n",
      "  Batch   560  of  12,218.    Elapsed: 0:07:44.\n",
      "  Batch   600  of  12,218.    Elapsed: 0:08:18.\n",
      "  Batch   640  of  12,218.    Elapsed: 0:08:51.\n",
      "  Batch   680  of  12,218.    Elapsed: 0:09:24.\n",
      "  Batch   720  of  12,218.    Elapsed: 0:09:57.\n",
      "  Batch   760  of  12,218.    Elapsed: 0:10:30.\n",
      "  Batch   800  of  12,218.    Elapsed: 0:11:03.\n",
      "  Batch   840  of  12,218.    Elapsed: 0:11:37.\n",
      "  Batch   880  of  12,218.    Elapsed: 0:12:10.\n",
      "  Batch   920  of  12,218.    Elapsed: 0:12:43.\n",
      "  Batch   960  of  12,218.    Elapsed: 0:13:16.\n",
      "  Batch 1,000  of  12,218.    Elapsed: 0:13:49.\n",
      "  Batch 1,040  of  12,218.    Elapsed: 0:14:22.\n",
      "  Batch 1,080  of  12,218.    Elapsed: 0:14:56.\n",
      "  Batch 1,120  of  12,218.    Elapsed: 0:15:29.\n",
      "  Batch 1,160  of  12,218.    Elapsed: 0:16:02.\n",
      "  Batch 1,200  of  12,218.    Elapsed: 0:16:35.\n",
      "  Batch 1,240  of  12,218.    Elapsed: 0:17:08.\n",
      "  Batch 1,280  of  12,218.    Elapsed: 0:17:41.\n",
      "  Batch 1,320  of  12,218.    Elapsed: 0:18:15.\n",
      "  Batch 1,360  of  12,218.    Elapsed: 0:18:48.\n",
      "  Batch 1,400  of  12,218.    Elapsed: 0:19:21.\n",
      "  Batch 1,440  of  12,218.    Elapsed: 0:19:54.\n",
      "  Batch 1,480  of  12,218.    Elapsed: 0:20:27.\n",
      "  Batch 1,520  of  12,218.    Elapsed: 0:21:00.\n",
      "  Batch 1,560  of  12,218.    Elapsed: 0:21:34.\n",
      "  Batch 1,600  of  12,218.    Elapsed: 0:22:07.\n",
      "  Batch 1,640  of  12,218.    Elapsed: 0:22:40.\n",
      "  Batch 1,680  of  12,218.    Elapsed: 0:23:13.\n",
      "  Batch 1,720  of  12,218.    Elapsed: 0:23:46.\n",
      "  Batch 1,760  of  12,218.    Elapsed: 0:24:19.\n",
      "  Batch 1,800  of  12,218.    Elapsed: 0:24:53.\n",
      "  Batch 1,840  of  12,218.    Elapsed: 0:25:26.\n",
      "  Batch 1,880  of  12,218.    Elapsed: 0:25:59.\n",
      "  Batch 1,920  of  12,218.    Elapsed: 0:26:32.\n",
      "  Batch 1,960  of  12,218.    Elapsed: 0:27:05.\n",
      "  Batch 2,000  of  12,218.    Elapsed: 0:27:39.\n",
      "  Batch 2,040  of  12,218.    Elapsed: 0:28:12.\n",
      "  Batch 2,080  of  12,218.    Elapsed: 0:28:45.\n",
      "  Batch 2,120  of  12,218.    Elapsed: 0:29:18.\n",
      "  Batch 2,160  of  12,218.    Elapsed: 0:29:51.\n",
      "  Batch 2,200  of  12,218.    Elapsed: 0:30:24.\n",
      "  Batch 2,240  of  12,218.    Elapsed: 0:30:58.\n",
      "  Batch 2,280  of  12,218.    Elapsed: 0:31:31.\n",
      "  Batch 2,320  of  12,218.    Elapsed: 0:32:04.\n",
      "  Batch 2,360  of  12,218.    Elapsed: 0:32:37.\n",
      "  Batch 2,400  of  12,218.    Elapsed: 0:33:10.\n",
      "  Batch 2,440  of  12,218.    Elapsed: 0:33:43.\n",
      "  Batch 2,480  of  12,218.    Elapsed: 0:34:17.\n",
      "  Batch 2,520  of  12,218.    Elapsed: 0:34:50.\n",
      "  Batch 2,560  of  12,218.    Elapsed: 0:35:23.\n",
      "  Batch 2,600  of  12,218.    Elapsed: 0:35:56.\n",
      "  Batch 2,640  of  12,218.    Elapsed: 0:36:29.\n",
      "  Batch 2,680  of  12,218.    Elapsed: 0:37:03.\n",
      "  Batch 2,720  of  12,218.    Elapsed: 0:37:36.\n",
      "  Batch 2,760  of  12,218.    Elapsed: 0:38:09.\n",
      "  Batch 2,800  of  12,218.    Elapsed: 0:38:42.\n",
      "  Batch 2,840  of  12,218.    Elapsed: 0:39:15.\n",
      "  Batch 2,880  of  12,218.    Elapsed: 0:39:48.\n",
      "  Batch 2,920  of  12,218.    Elapsed: 0:40:22.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation d'un seed pour avoir des résultats reproductibles\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Stockez la perte moyenne après chaque époque afin de pouvoir les tracer.\n",
    "loss_values = []\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Apprentissage\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Mesure du temps écoulé pour l'apprentisagge d'une epoch\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Réinitialisez la loss totale pour cette époque.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Model en training mode\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progrès mis à jour tous les 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculez le temps écoulé en minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Affichage de la progression\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "\n",
    "        # Sortir le batch training de notre dataloader \n",
    "\n",
    "        # Au fur et à mesure que nous déballons(\"unpack\") le batch, \n",
    "        # nous copierons également chaque tenseur sur le GPU en utilisant la méthode `to`.\n",
    "        \n",
    "        # Batchs contiennent trois pytorch tensors :\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Effacez toujours les gradients précédemment calculés avant d'effectuer une backward pass. \n",
    "        # PyTorch ne le fait pas automatiquement car l'accumulation des gradients est \"pratique lors de l'entrainement des RNN\".\n",
    "\n",
    "        model.zero_grad()  \n",
    "\n",
    "        # Effectuer une forward pass (évaluer le modèle sur ce batch d'entraînement).\n",
    "        # Cela renverra la perte/loss (plutôt que la sortie du modèle) car nous avons fourni les `labels`.\n",
    "\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # L'appel à `model` retourne toujours un tuple, \n",
    "        # nous devons donc extraire la valeur de perte/loss du tuple.\n",
    "\n",
    "        loss = outputs[0]\n",
    "        \n",
    "        # Accumuler la perte/loss d'entraînement sur tous les batchs afin de pouvoir calculer la perte/loss moyenne à la fin.\n",
    "        # «loss» est un Tensor contenant une valeur unique; \n",
    "        # la fonction `.item ()` renvoie simplement la valeur Python du tenseur.\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Effectuez une backward pass pour calculer les gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Fixez la norme des gradients à 1.0.\n",
    "        # Ceci permet d'éviter le problème des \"exploding gradients\".\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Mettez à jour les paramètres et faites un pas en utilisant le gradient calculé.\n",
    "\n",
    "        # L'optimiseur dicte la \"règle de mise à jour\" \n",
    "        # comment les paramètres sont modifiés en fonction de leurs gradients, du taux d'apprentissage, etc.\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Mis à jour du taux d'apprentissage(\"learning rate\")\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculez la perte moyenne sur les données d'entraînement. \n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Stockez la valeur de perte pour tracer la courbe d'apprentissage.\n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    # Après chaque epoch de training, mesure de  notre performance sur\n",
    "    # notre ensemble de validation.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Mettre le modèle en mode évaluation\n",
    "    model.eval()\n",
    "\n",
    "    # Suivre variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Suivre variables \n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        #Ajout batch au GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Sortir le batch training de notre dataloader \n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Dire au modèle de ne pas calculer ou stocker les gradients,\n",
    "        # économiser de la mémoire et accélérer la validation\n",
    "\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Calculer les logits\n",
    "\n",
    "            # Cela renverra les logits plutôt que la perte car nous n'avons pas fourni d'étiquettes.\n",
    "\n",
    "            # token_type_ids est le même que les \"segment ids\", \n",
    "            # qui différencient les phrases 1 et 2 dans les tâches à 2 phrases.\n",
    "\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "            \n",
    "        # Prendre les logits sortis par le modèle    \n",
    "        logits = outputs[0]\n",
    "        \n",
    "        # Les \"logits\" sont les valeurs de sortie avant d'appliquer une fonction d'activation comme le softmax.\n",
    "\n",
    "        # Déplacer les logits et les labels vers le CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculez la précision  pour ce batch pour les phrases test.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "  \n",
    "        # Somme pour la précision totale\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Suivre/Actualiser le nombre de batch\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "         \n",
    "    # Affichage de la précision finale de ce validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRWbE0zJT_jW"
   },
   "source": [
    "Nous avons réaliser un graphique pour observer la **perte/loss d'entrainement** du modèle en fonction des epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uwb6FXlZJsa_"
   },
   "outputs": [],
   "source": [
    "f = pd.DataFrame(loss_values)\n",
    "f.columns=['Loss']\n",
    "fig = px.line(f, x=f.index, y=f.Loss)\n",
    "fig.update_layout(title='Training loss of the Model',\n",
    "                   xaxis_title='Epoch',\n",
    "                   yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR_jBlXOl0w1"
   },
   "source": [
    "Il est possible de rajouter certaines variables pour visualiser la présence ou non de **surapprentissage** ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGWUT1ffe6de"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> V Prédictions </h2></u>\n",
    "\n",
    "Maintenant que nous avons configuré, optimisé et entrainé notre modèle nous allons **prédire les labels** avec le jeu de données **test**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R14wOh8Qb9Xt"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> A - Configuration données test </h3></u>\n",
    "\n",
    "Tout d'abord il convient de configurer le jeu de données test comme le jeu de données train (Tokenization, Masque, Torch Tensor, Batch Size, DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4EWhmd8Jze7"
   },
   "outputs": [],
   "source": [
    "# Définition de sentences/labels\n",
    "sentences=test_df[\"description\"].values\n",
    "labels=train_label[0:54300].Category.values\n",
    "\n",
    "# Affichage du nombre de phrase\n",
    "print('Le jeu de données test comporte : {:,}\\n'.format(test_df.shape[0]),\"phrase\")\n",
    "\n",
    "# Tokenization du jeu de données test\n",
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad_sequences : réglages de la longueur maximale\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Attention masks\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "\n",
    "# Convertion en torch tensor\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Choix du batch size.  \n",
    "batch_size = 32 \n",
    "\n",
    "# Créer DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UioQMsRqUqAL"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Prédictions du jeu de données Test </h3></u>\n",
    "\n",
    "Nous allons à l'aide du modèle construire/prédire les **logits** des données test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hH4t1yKJ1vc"
   },
   "outputs": [],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "# Model en mode eval\n",
    "model.eval()\n",
    "\n",
    "# variables \n",
    "predictions , true_labels = [], []\n",
    "# predictions\n",
    "for batch in prediction_dataloader:\n",
    "\n",
    "  # Ajout batch au GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Dire au modèle de ne pas calculer ou stocker les gradients, économiser de la mémoire et accélérer la prédiction \n",
    "  with torch.no_grad():\n",
    "      # calculer les logits de prédiction.\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Déplacer les logits et labels vers CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Stockage des prédictions et des true labels \n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QETImfDSU0iG"
   },
   "source": [
    "\n",
    "\n",
    "Pour construire le vecteur de prédictions il faut garder le **labels** correspand au **logits maximal** pour chaque observations. Le tableau est un double tableau de taille **1697*32** ici. Le 32 correspond à la taille des batchs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbZD0VFRFUrr"
   },
   "outputs": [],
   "source": [
    "vect=[]\n",
    "for j in range(1696):\n",
    "  for i in range(32):\n",
    "    pred_labels = np.argmax(predictions[j][i], axis=0).flatten()\n",
    "    vect.append(pred_labels[0])\n",
    "for t in range(28):\n",
    "  pred_labels = np.argmax(predictions[1696][t], axis=0).flatten()\n",
    "  vect.append(pred_labels[0])\n",
    "  \n",
    "print(\"Le vecteur possède est:\",len(vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8AHvG9RVycE"
   },
   "source": [
    "Nous stockons nos prédictions dans un csv avec deux colonnes : la première correspondant à l'identifiant de l'observation elle s'appelle **Id** et la deuxième correspond aux labels prédit qui a pour nom **Category**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3AGW6S7Kbd1"
   },
   "outputs": [],
   "source": [
    "test_df[\"Category\"] = vect\n",
    "baseline_file = test_df[[\"Id\",\"Category\"]]\n",
    "baseline_file.to_csv(\"BERTAouf486_epoch2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWkiiE5hVUc2"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> VI Comparaison des prédictions pour différents modèles </h2></u>\n",
    "\n",
    "Il est possible de comparer les modèles sur leurs prédictions ce qui permet de voir quels sont les modèles les plus proches et permet de donnée une première idée du taux erreur possible en fonction de la proximité avec d'autre modèles où l'erreur de prédiction est connue.\n",
    "\n",
    "<u><h3><FONT color=\"darkgreen\"> A - Chargement des csv de prédictions </h3></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWd8YfUbFphL"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./\"\n",
    "\n",
    "# ROBERT\n",
    "\n",
    "# epoch = 1\n",
    "\n",
    "roberta480 = pd.read_csv(DATA_PATH+\"/ROBERTAouf480.csv\")\n",
    "roberta486 = pd.read_csv(DATA_PATH+\"/ROBERTAouf486.csv\")\n",
    "roberta320 = pd.read_csv(DATA_PATH+\"/ROBERTAouf320.csv\")\n",
    "\n",
    "# epoch = 2\n",
    "\n",
    "roberta484E2 = pd.read_csv(DATA_PATH+\"/ROBERTAouf484_Epoch2.csv\")\n",
    "robert_2e = pd.read_csv(DATA_PATH+\"/ROBERTAouf484_Epoch2.csv\")\n",
    "\n",
    "# BERT\n",
    "\n",
    "# epoch = 1\n",
    "bert480 = pd.read_csv(DATA_PATH+\"/BERTouf_480.csv\")\n",
    "bert_480 = pd.read_csv(DATA_PATH+\"/BERTouf_480.csv\")\n",
    "\n",
    "# epoch = 2\n",
    "bert_2e = pd.read_csv(DATA_PATH+\"/BERTouf486_e2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMHtOGytmO4c"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> B - Tableau du pourcentage de similitudes </h3></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNG1HYrlhTZ3"
   },
   "outputs": [],
   "source": [
    "print(sum(roberta480[\"Category\"]==roberta484E2[\"Category\"])/54300)\n",
    "print(sum(roberta486[\"Category\"]==roberta484E2[\"Category\"])/54300)\n",
    "\n",
    "print(sum(bert_2e[\"Category\"]==bert_480[\"Category\"])/54300)\n",
    "print(sum(robert_2e[\"Category\"]==bert_2e[\"Category\"])/54300)\n",
    "print(sum(robert_2e[\"Category\"]==bert_480[\"Category\"])/54300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGKjV0kOgWei"
   },
   "outputs": [],
   "source": [
    "tot_=sum(roberta480[\"Category\"]==roberta486[\"Category\"])/54300\n",
    "tot_diff2=sum(roberta320[\"Category\"]==roberta486[\"Category\"])/54300\n",
    "tot_diff3=sum(bert480[\"Category\"]==roberta486[\"Category\"])/54300\n",
    "print(tot_)\n",
    "print(tot_diff2)\n",
    "print(tot_diff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZrXq_cRFz8C"
   },
   "outputs": [],
   "source": [
    "tot_diff=sum(roberta480[\"Category\"]==roberta320[\"Category\"])/54300\n",
    "tot_diff3=sum(roberta480[\"Category\"]==bert480[\"Category\"])/54300\n",
    "print(tot_diff)\n",
    "print(tot_diff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czW41cBheqY9"
   },
   "outputs": [],
   "source": [
    "rob_epoch1=sum(roberta480[\"Category\"]==roberta320[\"Category\"])/54300\n",
    "rob_epoch2=sum(roberta480[\"Category\"]==bert480[\"Category\"])/54300\n",
    "rob_epoch3=sum(roberta320[\"Category\"]==bert480[\"Category\"])/54300\n",
    "print(rob_epoch1)\n",
    "print(rob_epoch2)\n",
    "print(rob_epoch3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I1NBn9Fdme1"
   },
   "source": [
    "<u><h3><FONT color=\"darkgreen\"> C - Coefficients de Matthews </h3></u>\n",
    "\n",
    "Cette partie est réalisable si seulement si on possède les labels du test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZz9sA5RJ49e"
   },
   "outputs": [],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwdIhsV4J-fU"
   },
   "outputs": [],
   "source": [
    "matthews_set = []\n",
    "# Évaluer chaque batch de test en utilisant le coefficient de corrélation de Matthew\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # Les prédictions pour ce batch sont un ndarray à 2-colonnes (une colonne pour \"0\" et une colonne pour \"1\"). \n",
    "  #Choisissez le label avec la valeur la plus élevée et transformez-la en une liste de 0s et 1s.\n",
    "\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculer et stocker le coef pour ce batch\n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8za_jenhKCR6"
   },
   "outputs": [],
   "source": [
    "matthews_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebVLJLzoKEqh"
   },
   "outputs": [],
   "source": [
    "# Combinez les prédictions pour chaque batch en une seule liste de 0s et 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "# Combinez les bonnes labels pour chaque batch en une seule liste.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Cacluer le MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9MoUnqAnsk2"
   },
   "source": [
    "<u><h2><FONT color=\"darkred\"> VII - Bibliographie </h2></u>\n",
    "\n",
    "<ul>\n",
    "  <li> https://towardsdatascience.com/fine-tuning-bert-and-roberta-for-high-accuracy-text-classification-in-pytorch-c9e63cf64646  </li>\n",
    "\n",
    "  <li>https://medium.com/@aniruddha.choudhury94/part-2-bert-fine-tuning-tutorial-with-pytorch-for-text-classification-on-the-corpus-of-linguistic-18057ce330e1 </li>\n",
    "  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Code_Bert_Roberta.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09566012c5a74db6a173a182dc38fcc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c482d1e26d944bd8743d29fad3463a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f422a87a7be466e8b5f322f971c5951": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd3a944c935747a082f0c663b56768eb",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ac8eeec6df84367b830d5a608729163",
      "value": 440473133
     }
    },
    "1ccd15e2d5c040a28473757def6cdade": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a01458e7ff444f90f47b9d07032818": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "281207d434c24f2e84458c89935a7723": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1546b4ecc9446e9a123a15975dab70d",
       "IPY_MODEL_36272b1d065b4421b66dcb999716feb5"
      ],
      "layout": "IPY_MODEL_25a01458e7ff444f90f47b9d07032818"
     }
    },
    "2c499e0133ad45b3b830c1968401456b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d587f83489a64e02a0b1648b54e11270",
      "placeholder": "​",
      "style": "IPY_MODEL_9351f61389db44189c3ec0af0db7d5d6",
      "value": " 232k/232k [00:00&lt;00:00, 805kB/s]"
     }
    },
    "36272b1d065b4421b66dcb999716feb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c482d1e26d944bd8743d29fad3463a2",
      "placeholder": "​",
      "style": "IPY_MODEL_446e2c3e4086427c9a117844b8aa3b28",
      "value": " 433/433 [00:09&lt;00:00, 47.6B/s]"
     }
    },
    "3ac8eeec6df84367b830d5a608729163": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "446e2c3e4086427c9a117844b8aa3b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58e906e24b8447c9b70514447e032d2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75e7decdab154627a28e8b5f1b6cdc77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f422a87a7be466e8b5f322f971c5951",
       "IPY_MODEL_a8038feefeab48fdb24f15ef73bff068"
      ],
      "layout": "IPY_MODEL_58e906e24b8447c9b70514447e032d2c"
     }
    },
    "9351f61389db44189c3ec0af0db7d5d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1546b4ecc9446e9a123a15975dab70d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3cfc9aa03f14b64a77feb7e64172f5a",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09566012c5a74db6a173a182dc38fcc3",
      "value": 433
     }
    },
    "a8038feefeab48fdb24f15ef73bff068": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1d0216da1f24c88a783fcca32ab5cb2",
      "placeholder": "​",
      "style": "IPY_MODEL_d19a08708d1c475ab0990d13741ffe8b",
      "value": " 440M/440M [00:05&lt;00:00, 75.0MB/s]"
     }
    },
    "b3cfc9aa03f14b64a77feb7e64172f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd3a944c935747a082f0c663b56768eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca00784f70524631aed7564bf0df305e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d19a08708d1c475ab0990d13741ffe8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d587f83489a64e02a0b1648b54e11270": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d67cde4838a149b7b35715c143d6610f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca00784f70524631aed7564bf0df305e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d75693031a5844fda7d83a222adfc4a0",
      "value": 231508
     }
    },
    "d75693031a5844fda7d83a222adfc4a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1d0216da1f24c88a783fcca32ab5cb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fffbc26887b2448fb4d4cd37c770c0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d67cde4838a149b7b35715c143d6610f",
       "IPY_MODEL_2c499e0133ad45b3b830c1968401456b"
      ],
      "layout": "IPY_MODEL_1ccd15e2d5c040a28473757def6cdade"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
